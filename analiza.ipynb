{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gdown\n",
    "from thefuzz import process\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Downloading data\n",
    "file_id_1 = '1s0zEHlvgbIr4AKruko2yFQymK_Pp1QNi'\n",
    "file_id_2 = '1sTnKn_XSgZ_8uzNo8INDtmz9WjIqziYG'\n",
    "file_id_3 = '1WuCNd7d4ZUJ8OQPmGtvMk_2Fasr9v0v2'\n",
    "url_1 = f\"https://drive.google.com/uc?id={file_id_1}\"\n",
    "url_2 = f\"https://drive.google.com/uc?id={file_id_2}\"\n",
    "url_3 = f\"https://drive.google.com/uc?id={file_id_3}\"\n",
    "output_1 = 'data_dv.csv'\n",
    "output_2 = 'data_ev.csv'\n",
    "output_3 = 'data_ur.csv'\n",
    "gdown.download(url_1, output_1, quiet=False)\n",
    "gdown.download(url_2, output_2, quiet=False)\n",
    "gdown.download(url_3, output_3, quiet=False)\n",
    "df1 = pd.read_csv(output_1)\n",
    "df2 = pd.read_csv(output_2)\n",
    "df3 = pd.read_csv(output_3,sep = ';')\n",
    "\n",
    "# Viewing data\n",
    "df1.head()\n",
    "df2.head()\n",
    "df3.head()\n",
    "\n",
    "#Cleaning data and changing name col\n",
    "df1['disitrict_name'] = df1['disitrict_name'].astype(str)\n",
    "df2['Disitrict'] = df2['Disitrict'].astype(str)\n",
    "df2['district_clean'] = df2['Disitrict'].apply(lambda x:process.extractOne(x,df1['disitrict_name'])[0])\n",
    "df3.drop(columns=['Kod','Unnamed: 3'], inplace=True)\n",
    "df3.rename(columns={'Nazwa':'district_name','ogółem;2023;[%]':'unemployment_rate'},inplace=True)\n",
    "df3['district_clean3'] = df3['district_name'].apply(lambda x: process.extractOne(x,df1['disitrict_name'])[0])\n",
    "\n",
    "#Merging data into one DF\n",
    "df_merged = df1.merge(df2,left_on='disitrict_name',right_on='district_clean',how='inner')\n",
    "df_merged = df_merged.merge(df3,left_on='disitrict_name',right_on='district_clean3', how='inner')\n",
    "df_merged.head()\n",
    "df_merged.rename(columns = {'disitrict_name':'district_name'},inplace=True)\n",
    "df_merged.drop(columns=['Disitrict','district_clean','district_clean3'], inplace=True)\n",
    "df_merged.dropna(inplace=True)\n",
    "df_merged.info()\n",
    "float_list = ['salary','education_expenses']\n",
    "for i in float_list:\n",
    "    df_merged[i] = df_merged[i].astype(str)\n",
    "    df_merged[i] = df_merged[i].apply(lambda x:x.replace(',',''))\n",
    "    df_merged[i] = df_merged[i].astype(float)\n",
    "\n",
    "df_merged['unemployment_rate'] = df_merged['unemployment_rate'].str.replace(',','.')\n",
    "df_merged['unemployment_rate'] = df_merged['unemployment_rate'].astype(float)\n",
    "df_merged.drop_duplicates(subset = ['district_name'], keep ='first', inplace = True)\n",
    "df_merged.head()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T13:47:20.273746Z",
     "start_time": "2025-03-28T13:47:20.253790Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Linear regression OLS method without scaling\n",
    "X = df_merged[['salary','education_expenses','unemployment_rate','divorces']]\n",
    "y = df_merged['mean_score']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "model_OLS = LinearRegression()\n",
    "model_OLS.fit(X_train, y_train)\n",
    "R2 = model_OLS.score(X_test, y_test)\n",
    "df_intercept = pd.DataFrame(model_OLS.intercept_,['Intercept'],columns=['Value'])\n",
    "df_coef = pd.DataFrame(model_OLS.coef_,X.columns,columns=['Value'])\n",
    "df_equation = pd.concat([df_intercept, df_coef],ignore_index=False)\n",
    "\n",
    "# Validation of model\n",
    "y_pred_OLS = model_OLS.predict(X_test)\n",
    "mae_OLS = mean_absolute_error(y_test, y_pred)\n",
    "mse_OLS = mean_squared_error(y_test, y_pred)\n",
    "r2_OLS = r2_score(y_test, y_pred)\n",
    "rmse_OLS = np.sqrt(mse_OLS)\n",
    "\n",
    "# Creating data frane of results\n",
    "df_results_OLS = pd.DataFrame([mae_OLS, mse_OLS, r2_OLS, rmse_OLS], index=['MAE','MSE','R2','RMSE'],columns=['Value'])\n",
    "print(df_results_OLS)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Value\n",
      "MAE    5.855805\n",
      "MSE   53.003729\n",
      "R2     0.041051\n",
      "RMSE   7.280366\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "#plt.scatter(y=Y,x=df_merged['unemployment_rate'])",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
